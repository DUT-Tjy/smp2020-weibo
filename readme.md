由于模型过大，以下部分只提供训练、测试流程及部分结果。
1、在train文件夹下运行preprocess.ipynb对数据进行5折划分，并将生成的data_StratifiedKFold_42文件夹拷贝到model/data文件夹下
2、下载roberta_wwm_large预训练模型到model/model/RoBERTa_zh_Large_PyTorch文件夹下
3、运行model/source文件夹中的run_finetune.sh文件对roberta_wwm_large预训练模型进行微调，在model/model文件夹下生成微调后的模型roberta_fine_8
4、分别运行model/source文件夹中的run_bert_base.sh、run_bert_gru.sh、run_bert_last2embedding.sh进行训练，在model/model文件夹下生成roberta_fine_base、roberta_fine_gru、roberta_fine_last2embedding文件夹。
5、在test文件夹下运行preprocess.ipynb生成test.csv，使用生成的test.csv文件替换model/data/data_StratifiedKFold_42文件夹内的所有test.csv文件，分别运行model/source文件夹中的run_bert_base_test.sh、run_bert_gru_test.sh、run_bert_last2embedding_test.sh进行预测。
6、将model/model/roberta_fine_base、model/model/roberta_fine_gru、model/model/roberta_fine_last2embedding文件夹下bert_large_0至bert_large_4文件夹中的sub.csv文件拷贝出来，重新命名为sub_0至sub_4，放入test文件夹下的fine_base、fine_gru、fine_last2embedding文件夹中，在test文件夹下运行final_result.ipynb得到最终结果。
